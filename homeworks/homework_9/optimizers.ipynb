{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "use_gpu = False\n",
    "device = 'cuda' if torch.cuda.is_available() and use_gpu else 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Задание 1**\n",
    "\n",
    "Написать на PyTorch forward и backward полносвязного слоя без использования autograd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [],
   "source": [
    "# Функция активации и ее производная\n",
    "def sigmoid (x):\n",
    "    return 1/(1 + torch.exp(-x))\n",
    "\n",
    "def derivatives_sigmoid(x):\n",
    "    return x * (1 - x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features=input_dim, out_features=output_dim)\n",
    "        self.activation = sigmoid\n",
    "        self.saved_tensors = None\n",
    "\n",
    "    def forward(self, input_x):\n",
    "        self.saved_tensors = input_x\n",
    "        return self.activation(self.linear(input_x))\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * derivatives_sigmoid(self.saved_tensors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "test_tensor = torch.rand([9, 9]).to(device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "data": {
      "text/plain": "NN(\n  (linear): Linear(in_features=9, out_features=9, bias=True)\n)"
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NN(input_dim=9, output_dim=9)\n",
    "model.train()\n",
    "model.to(device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.5541, 0.5383, 0.4738, 0.6457, 0.5474, 0.6664, 0.5918, 0.4006, 0.4379],\n        [0.5459, 0.5670, 0.5318, 0.5698, 0.4788, 0.6731, 0.5361, 0.3977, 0.4624],\n        [0.5440, 0.5672, 0.4988, 0.5366, 0.5123, 0.6452, 0.4958, 0.3895, 0.4970],\n        [0.5569, 0.5453, 0.4865, 0.5086, 0.4844, 0.6084, 0.5532, 0.4196, 0.4661],\n        [0.5443, 0.6556, 0.4524, 0.5720, 0.4954, 0.6671, 0.5224, 0.4532, 0.4831],\n        [0.5482, 0.6074, 0.4579, 0.5372, 0.4936, 0.6083, 0.5206, 0.4317, 0.4671],\n        [0.5610, 0.5971, 0.4463, 0.6407, 0.5313, 0.6478, 0.5520, 0.4025, 0.4591],\n        [0.5688, 0.5629, 0.4711, 0.5275, 0.5205, 0.6105, 0.5831, 0.3888, 0.4759],\n        [0.5879, 0.5134, 0.4587, 0.5353, 0.5178, 0.6085, 0.6095, 0.3873, 0.4556]],\n       grad_fn=<MulBackward0>)"
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model(test_tensor)\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Задание 2**\n",
    "\n",
    "Написать 1-2 адаптивных оптимизатора\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [],
   "source": [
    "# Пример из лекции\n",
    "class SDGMomentum:\n",
    "    def __init__(self, momentum, lr, model):\n",
    "        self.momentum = momentum\n",
    "        self.lr = lr\n",
    "        self.velocity = torch.zeros_like(model)\n",
    "        self.model = model\n",
    "\n",
    "    def step(self, grad):\n",
    "        self.velocity = self.momentum * self.velocity - self.lr * grad\n",
    "        self.model += self.velocity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__(self, lr, model):\n",
    "        self.accumulated = torch.zeros_like(model)\n",
    "        self.lr = lr\n",
    "        self.adapt_lr = lr\n",
    "        self.model = model\n",
    "\n",
    "    def step(self, grad):\n",
    "        self.accumulated += grad**2\n",
    "        self.adapt_lr = self.lr / torch.sqrt(self.accumulated)\n",
    "        self.model -= self.adapt_lr * grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [],
   "source": [
    "class RMSprop:\n",
    "    def __init__(self, rho, lr, model):\n",
    "        self.accumulated = torch.zeros_like(model)\n",
    "        self.rho = rho\n",
    "        self.lr = lr\n",
    "        self.adapt_lr = lr\n",
    "        self.model = model\n",
    "\n",
    "    def step(self, grad):\n",
    "        self.accumulated += self.rho * self.accumulated + (1 - self.rho) * grad**2\n",
    "        self.adapt_lr = self.lr / torch.sqrt(self.accumulated)\n",
    "        self.model -= self.adapt_lr * grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Задание 3**\n",
    "\n",
    "Решить задачу нахождения корней квадратного уравнения методом градиентного спуска"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return (3 * x + 9) ** 2\n",
    "\n",
    "def grad_f(x):\n",
    "    return 2 * (3 * x + 9)\n",
    "\n",
    "def solver(init_x, optimizer, max_iter=1000):\n",
    "    g = grad_f(init_x)\n",
    "    optim = optimizer\n",
    "    for i in range(max_iter):\n",
    "        optim.step(g)\n",
    "        g = grad_f(optim.model)\n",
    "    print(optim.model)\n",
    "    return optim.model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(6.)\n",
    "_ = solver(init_x=x, optimizer=SDGMomentum(lr=0.01, momentum=0.95, model=x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.0000)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(6.)\n",
    "_ = solver(init_x=x, optimizer=AdaGrad(lr=0.3, model=x), max_iter=10000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(6.)\n",
    "_ = solver(init_x=x, optimizer=RMSprop(lr=0.9, rho=0.99, model=x), max_iter=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}